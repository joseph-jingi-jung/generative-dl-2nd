{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "import torchvision\n",
    "import torchvision.transforms.v2 as v2\n",
    "import torchvision.datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 100x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "transform = v2.Compose([\n",
    "    v2.Pad(2),\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./dataset', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./dataset', train=False, transform=transform, download=True)\n",
    "\n",
    "x, y = train_dataset[0]\n",
    "print(x.shape)\n",
    "x = x.squeeze(0)\n",
    "plt.figure(figsize=(1,1))\n",
    "plt.imshow(x, cmap='grey')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 32, 32])\n",
      "torch.Size([1, 1])\n",
      "tensor([[0.0331]], grad_fn=<SiluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class Ebm(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.activation = nn.SiLU()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=5, stride=2, padding=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2, padding=1)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dense = nn.Linear(in_features=64, out_features=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.activation(out)\n",
    "        \n",
    "        out = self.conv2(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv4(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.conv5(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        out = self.flatten(out)\n",
    "        out = self.dense(out)\n",
    "        out = self.activation(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "model = Ebm()\n",
    "sample = train_dataset[0][0].unsqueeze(0)\n",
    "print(sample.shape)\n",
    "out = model(sample)\n",
    "print(out.shape)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_samples(model, inp_imgs, steps, step_size, noise):\n",
    "    imgs_per_step = []\n",
    "    for _ in range(steps):\n",
    "        # add noise\n",
    "        inp_imgs += torch.randn(inp_imgs.shape, device=inp_imgs.device) * noise # noise : stddev\n",
    "        inp_imgs = torch.clip(inp_imgs, min=-1.0, max=1.0)\n",
    "        \n",
    "        # get energy score\n",
    "        out_score = -model(inp_imgs)\n",
    "\n",
    "        # calculate gradiant\n",
    "        grads = torch.autograd.grad(\n",
    "            outputs=out_score, \n",
    "            inputs=inp_imgs, \n",
    "            retain_graph=True,\n",
    "            grad_outputs=torch.ones_like(out_score))[0]\n",
    "    \n",
    "        grads = torch.clip(grads, min=-0.03, max=0.03)\n",
    "\n",
    "        # add gradiant to image\n",
    "        inp_imgs += -step_size * grads\n",
    "        inp_imgs = torch.clip(inp_imgs, min=-1.0, max=1.0)\n",
    "        imgs_per_step.append(inp_imgs)\n",
    "\n",
    "    return inp_imgs, imgs_per_step\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Generating samples from model to train\n",
    "class Buffer:\n",
    "    def __init__(self, model, batch_size, device) -> None:\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.batch_size = batch_size\n",
    "        self.device = device\n",
    "        self.examples = [\n",
    "            torch.rand([1, 1,32,32], device=device) * 2 - 1 for _ in range(batch_size)\n",
    "        ]\n",
    "    \n",
    "    def sample_new_exmps(self, steps, step_size, noise):\n",
    "        n_new = np.random.binomial(self.batch_size, 0.05)\n",
    "        rand_imgs = (\n",
    "            torch.rand([n_new, 1, 32,32], requires_grad=True, device=device) * 2 - 1\n",
    "        )\n",
    "        choice_d = random.choices(self.examples, k=(self.batch_size - n_new))\n",
    "        old_imgs = torch.cat(\n",
    "            choice_d, dim=0\n",
    "        )\n",
    "        inp_imgs = torch.cat([rand_imgs, old_imgs], dim=0)\n",
    "        inp_imgs = inp_imgs.to(device)\n",
    "        inp_imgs, _ = generate_samples(\n",
    "            self.model, inp_imgs, steps, step_size, noise\n",
    "        )\n",
    "        self.examples = list(torch.split(inp_imgs, 1, dim=0))  + self.examples\n",
    "        self.examples = self.examples[:8192]\n",
    "        return inp_imgs\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "buffer = Buffer(model, 16, device)\n",
    "res = buffer.sample_new_exmps(steps=60, step_size=10, noise=0.005)\n",
    "print(res.shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/469 [00:00<02:57,  2.64it/s, [0] loss:-0.00587]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 45\u001b[0m\n\u001b[0;32m     43\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[0;32m     44\u001b[0m dl \u001b[38;5;241m=\u001b[39m DataLoader(dataset\u001b[38;5;241m=\u001b[39mtrain_dataset, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m---> 45\u001b[0m loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[104], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, buffer, optimizer, n_epoch, dataloader, device)\u001b[0m\n\u001b[0;32m     27\u001b[0m     n_total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \n\u001b[0;32m     29\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mset_postfix_str(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] loss:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontrastive_divergence_loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 30\u001b[0m     \u001b[43mcontrastive_divergence_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     33\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m loss_sum \u001b[38;5;241m/\u001b[39m n_total\n",
      "File \u001b[1;32mc:\\Users\\devbi\\miniconda3\\envs\\torch_2.4.0\\Lib\\site-packages\\torch\\_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    520\u001b[0m     )\n\u001b[1;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devbi\\miniconda3\\envs\\torch_2.4.0\\Lib\\site-packages\\torch\\autograd\\__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\devbi\\miniconda3\\envs\\torch_2.4.0\\Lib\\site-packages\\torch\\autograd\\graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "def train(model, buffer, optimizer, n_epoch, dataloader, device):\n",
    "    pbar = tqdm(dataloader)\n",
    "    loss_history = []\n",
    "    model.train()\n",
    "    for epoch in range(n_epoch):\n",
    "        loss_sum = 0\n",
    "        n_total = 0 \n",
    "        for _, (x, _) in enumerate(pbar):\n",
    "            optimizer.zero_grad()\n",
    "            # add random noise to data to prevent overfitting\n",
    "            x += torch.randn_like(x) * 0.005 # 0.005 is stddev\n",
    "            x = torch.clip(x, -1.0, 1.0)\n",
    "            x = x.to(device)\n",
    "            \n",
    "            # get samples from buffer\n",
    "            fake_imgs = buffer.sample_new_exmps(steps=60, step_size=10, noise=0.005)\n",
    "            inp_imgs = torch.concat([x, fake_imgs], dim = 0)\n",
    "            real_out, fake_out = torch.vsplit(model(inp_imgs), 2)\n",
    "\n",
    "            # loss : -(\\nabla model(x_train) - \\nabla model(x_sample))\n",
    "            contrastive_divergence_loss = -(\n",
    "                torch.mean(real_out, dim=0) # x_train\n",
    "                - torch.mean(fake_out, dim = 0) #x_sample\n",
    "                )\n",
    "            \n",
    "            loss_sum += contrastive_divergence_loss.item() * x.shape[0]\n",
    "            n_total += x.shape[1] \n",
    "                    \n",
    "            pbar.set_postfix_str(f\"[{epoch}] loss:{contrastive_divergence_loss.item():.5f}\")\n",
    "            contrastive_divergence_loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        epoch_loss = loss_sum / n_total\n",
    "        loss_history.append(epoch_loss)\n",
    "    \n",
    "    return loss_history\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "batch_size = 128\n",
    "\n",
    "model = model.to(device)\n",
    "buffer = Buffer(model, batch_size, device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "dl = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "loss_history = train(model, buffer, optimizer, 50, dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_2.4.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
